{"cells":[{"cell_type":"markdown","metadata":{"id":"OWJu-9cBEK-3"},"source":["# Fondamenti di elaborazione immagini"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"dzFGeQLlERVB"},"source":["## Effettuiamo l'import delle librerie utilizzate nell'esercitazione."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":240,"status":"ok","timestamp":1678897127941,"user":{"displayName":"Federico Baire","userId":"14830023662958388668"},"user_tz":-60},"id":"nHv3RfuaEK-_"},"outputs":[],"source":["import cv2\n","import numpy as np\n","import matplotlib as mapli\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.axes_grid1 import ImageGrid\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"jmtpjLq3EK_C"},"source":["Di seguito i riferimenti alle pagine di documentazione, sempre utiliti:\n","\n","* Rif: [numpy](https://numpy.org/doc/stable/)\n","* Rif: [opencv](https://docs.opencv.org/)\n","* Rif: [matplotlib](https://matplotlib.org/stable/index.html)"]},{"cell_type":"markdown","metadata":{"id":"5uxgBIbvEK_G"},"source":["Aggiungiamo alcune funzioni di utilita' per semplificare la scrittura del codice."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":298,"status":"ok","timestamp":1678897145738,"user":{"displayName":"Federico Baire","userId":"14830023662958388668"},"user_tz":-60},"id":"89i_h7-qEK_H"},"outputs":[],"source":["def rgb(image : np.array) -> np.array:\n","    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","def gray(image : np.array) -> np.array:\n","    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","def grid(images : list[np.array], rows : int, cols : int, size : int, colors : list[str] = None) -> None:\n","    fig = plt.figure(figsize=(size,size))\n","    grid = ImageGrid(fig, 111, nrows_ncols=(rows, cols), axes_pad=0.1)\n","\n","    if colors is not None:\n","        counter = 0\n","        for ax, im in zip(grid, images):\n","            ax.imshow(im, cmap=colors[counter])\n","            counter = (counter + 1) % len(colors)\n","        plt.show()\n","    else:\n","        for ax, im in zip(grid, images):\n","            ax.imshow(im)\n","        plt.show()"]},{"cell_type":"markdown","metadata":{"id":"wB_MWJU9EK_O"},"source":["## _Sappiamo che le immagini sono matrici di numeri e, in quanto tali, operazioni aritmentiche elemento per elemento sono permesse e significative._"]},{"cell_type":"markdown","metadata":{"id":"60q-h2z9Ec7F"},"source":["Le operazioni applicabili sono molte e combinabili fra loro percio', di seguito, mostreremo solo alcuni esempi."]},{"cell_type":"markdown","metadata":{"id":"CZ1jvphrEK_P"},"source":["Immaginiamo ad esempio di voler creare una serie di immagini sintetiche che poi saranno utilizzate per addestrare un sistema di localizzazione automatica: _un localizzatore di mele nel cielo_. Il cielo ha mille sfumature, altrettante ne hanno le mele. Combinando cieli e mele potremmo ottenere un buon dataset."]},{"cell_type":"markdown","metadata":{"id":"kdEpMbodEK_Q"},"source":["Carichiamo una immagine di sfondo, il cielo e un'immagine in primo piano, la mela. Quest'ultima non e' semplicemente una immagine a 3 canali ma a 4 dove il quarto canale rappresenta il livello di trasparenza. Per caricare l'immagine nella sua interezza, senza escludere il canale della trasparenza, utilizziamo il flag _cv2.IMREAD_UNCHANGED_ della funzione _imread_."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":596,"status":"ok","timestamp":1678897272627,"user":{"displayName":"Federico Baire","userId":"14830023662958388668"},"user_tz":-60},"id":"P3-XRoF9EK_V"},"outputs":[],"source":["apple = cv2.imread('./imgs/apples/apple_1.png', cv2.IMREAD_UNCHANGED)\n","sky = cv2.imread('./imgs/skies/sky_1.png')\n","_, apple_mask = cv2.threshold(apple[:,:,3], 0, 255, cv2.THRESH_BINARY)\n","\n","grid([rgb(apple), rgb(sky), rgb(apple_mask)], 1, 3, 30)"]},{"cell_type":"markdown","metadata":{"id":"ypp89r3OEK_W"},"source":["Per fare una sovrapposizione che tenga conto della trasparenza, e' necessario conoscere dove l'oggetto in primo piano, la mela, si trova e dove no. Una maschera binaria rappresentera' queste informazioni in due colori dai valori, rispettivamente, di 0 e 1. Per ottenere questo, dividiamo l'immagine per 255 e ne riportiamo il formato ad 8 bit senza segno (0-255)."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1678897276641,"user":{"displayName":"Federico Baire","userId":"14830023662958388668"},"user_tz":-60},"id":"WwCLZ4lwEK_W"},"outputs":[],"source":["apple_mask = (apple_mask / 255).astype(np.uint8)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1678897276641,"user":{"displayName":"Federico Baire","userId":"14830023662958388668"},"user_tz":-60},"id":"jyIgu6TWEK_X"},"outputs":[],"source":["apple_mask = rgb(apple_mask)    # convertiamo nel piano RGB per la visualizzazione e per portare le immagini a 3 dimensioni.\n","apple_no_sky = rgb(apple)       # convertiamo nel piano RGB per la visualizzazione e per portare le immagini a 3 dimensioni.\n","sky_no_apple = rgb(sky)         # convertiamo nel piano RGB per la visualizzazione e per portare le immagini a 3 dimensioni."]},{"cell_type":"markdown","metadata":{"id":"qgrCd3x-EK_Y"},"source":["A questo punto le immagini hanno la stessa dimensione e lo stesso formato. E' possibile applicare una moltiplicazione pixel a pixel per escludere la mela dal cielo e il cielo dalla mela. Per farlo utiliziamo una il metodo _multiply_ di _opencv_.\n","\n","* Rif: [multiply](https://docs.opencv.org/4.7.0/d2/de8/group__core__array.html#ga979d898a58d7f61c53003e162e7ad89f)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":290,"status":"ok","timestamp":1678897278797,"user":{"displayName":"Federico Baire","userId":"14830023662958388668"},"user_tz":-60},"id":"cpAYjujhEK_Z"},"outputs":[],"source":["apple_no_sky = cv2.multiply(apple_mask, apple_no_sky)\n","sky_no_apple = cv2.multiply(1 - apple_mask, sky_no_apple)\n","\n","grid([apple_no_sky, sky_no_apple], 1, 2, 30)"]},{"cell_type":"markdown","metadata":{"id":"yyXhhfybEK_Z"},"source":["Sovrapponiamo le immagini con una semplice somma. In questo caso, abbiamo la garanzia di non sforare il range 0-255. Usiamo il metodo _add_ di _opencv_.\n","\n","* Rif: [add](https://docs.opencv.org/4.7.0/d2/de8/group__core__array.html#ga10ac1bfb180e2cfda1701d06c24fdbd6) "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":255,"status":"ok","timestamp":1678897285964,"user":{"displayName":"Federico Baire","userId":"14830023662958388668"},"user_tz":-60},"id":"XfGpEYgnEK_a"},"outputs":[],"source":["apple_in_the_sky = cv2.add(apple_no_sky, sky_no_apple)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":258},"executionInfo":{"elapsed":1048,"status":"ok","timestamp":1678897287742,"user":{"displayName":"Federico Baire","userId":"14830023662958388668"},"user_tz":-60},"id":"LryQM5EKEK_a","outputId":"cab559da-e3dc-4993-e408-4db4da9eb0fa"},"outputs":[],"source":["grid([apple_no_sky, sky_no_apple, apple_mask*255, apple_in_the_sky], 1, 4, 30)"]},{"cell_type":"markdown","metadata":{"id":"qFbOUyOMEK_c"},"source":["Se avessimo sovrapposto le immagini con una semplice somma pesata, senza tenere conto della traspareza, avremmo ottenuto un risultato accettabile ma non realistico. Il metodo in questione e' _addWeighted_ di _opencv_ dove va indicato, per ogni sorgente, quanto percentualmente quest'ultima influira'.\n","\n","* Rif: [addWeighted](https://docs.opencv.org/4.7.0/d2/de8/group__core__array.html#gafafb2513349db3bcff51f54ee5592a19)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":328},"executionInfo":{"elapsed":2798,"status":"ok","timestamp":1678897348812,"user":{"displayName":"Federico Baire","userId":"14830023662958388668"},"user_tz":-60},"id":"GQWajYoVEK_e","outputId":"9a0ff158-70ee-4c9c-99eb-0e85f15d2d12"},"outputs":[],"source":["apple = cv2.imread('./imgs/apples/apple_1.png')\n","sky = cv2.imread('./imgs/skies/sky_1.png')\n","\n","weighted_sky_with_apple = cv2.addWeighted(apple, 0.5, sky, 0.5, -1)\n","grid([rgb(apple), rgb(sky), rgb(weighted_sky_with_apple)], 1, 3, 30)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["grid([apple_in_the_sky, rgb(weighted_sky_with_apple)], 1, 2, 30)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"corso_ai","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"55b72797edd57f58696da9ac5b5536b8813fefe094e8c8c02c797501a07dae2a"}}},"nbformat":4,"nbformat_minor":0}
