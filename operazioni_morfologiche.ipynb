{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"9QFaY8irHdYj"},"source":["# Fondamenti di elaborazione immagini"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"DTgER4fVHkcZ"},"source":["## _Effettuiamo l'import delle librerie utilizzate nell'esercitazione._"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-7PVHXx_HdYp"},"outputs":[],"source":["import cv2\n","import numpy as np\n","import matplotlib as mapli\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.axes_grid1 import ImageGrid\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"L6P-3mZmHdYt"},"source":["Di seguito i riferimenti alle pagine di documentazione, sempre utiliti:\n","\n","* Rif: [numpy](https://numpy.org/doc/stable/)\n","* Rif: [opencv](https://docs.opencv.org/)\n","* Rif: [matplotlib](https://matplotlib.org/stable/index.html)"]},{"cell_type":"markdown","metadata":{"id":"KckTp-UeHdYu"},"source":["Aggiungiamo alcune funzioni di utilita' per la scrittura del codice."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4FE6_x8hHdYv"},"outputs":[],"source":["def rgb(image : np.array) -> np.array:\n","    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","def gray(image : np.array) -> np.array:\n","    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","def grid(images : list[np.array], rows : int, cols : int, size : int, colors : list[str] = None) -> None:\n","    fig = plt.figure(figsize=(size,size))\n","    grid = ImageGrid(fig, 111, nrows_ncols=(rows, cols), axes_pad=0.1)\n","\n","    if colors is not None:\n","        counter = B\n","        for ax, im in zip(grid, images):\n","            ax.imshow(im, cmap=colors[counter])\n","            counter = (counter + 1) % len(colors)\n","        plt.show()\n","    else:\n","        for ax, im in zip(grid, images):\n","            ax.imshow(im)\n","        plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"4ycFRAL7HoI_"},"source":["## _Opencv mette a disposizione alcune delle operazioni morfologiche piu' utilizzate._"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"VFlYStn_HdYx"},"source":["Il punto di partenza di molte di queste è la definizione dell'elemento strutturale, o kernel, che va poi ad eseguire il movimento di convoluzione sull'immagine sorgente, generando l'output. La definizione del kernel puo' essere fatta semplicemente con _numpy_.\n","\n","* Rif: [Structuring element](https://en.wikipedia.org/wiki/Structuring_element)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E7-gDBhHHdYy","outputId":"899d3357-8d23-42ec-998c-55d2bda11275"},"outputs":[],"source":["kernel_sample = np.array([[0, 0, 0],\n","                          [0, 1, 0],\n","                          [0, 0, 0]])\n","\n","print(kernel_sample)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"QkvnnCSQHdY3"},"source":["Per gli esempi successivi ci concentriamo su immagini binarie."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KRqekJGmHdY4","outputId":"e2380099-951e-4b87-d003-90d9c9c17e1b"},"outputs":[],"source":["# carichiamo una immagine di esempio.\n","image = cv2.imread('./imgs/blobs.png', cv2.IMREAD_GRAYSCALE)\n","\n","print(f'Dimensione: {image.shape}')\n","grid([image], 1, 1, 5)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"jvo9T7goHdY8"},"source":["## _Con opencv e' possibile eseguire l'erosione._ "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"IZ34MwIyHuPQ"},"source":["Per applicare l'erosione, possiamo partire definendo un kernel quadrato di dimensione dispari e pieno di valori ad 1."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OdlVGcucHdY_","outputId":"eaf3faad-574d-4112-8fc7-7122997c9f47"},"outputs":[],"source":["se_erode_size = 5\n","se_erode_shape = (se_erode_size, se_erode_size)\n","se_erode = np.ones(se_erode_shape, np.uint8)\n","\n","print(se_erode)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kFO0z8NbHdZA","outputId":"b2f6968d-08a8-4d9f-9cdb-fe6da3250c1e"},"outputs":[],"source":["image_with_erode = cv2.erode(image, se_erode, iterations = 1)\n","\n","grid([image, image_with_erode], 1, 2, 20)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Con il metodo _erode_ esposto da _opencv_, il kernel definito è stato fatto passare di pixel in pixel ed ha eroso tuti i pixel per i quali il vicinato non ha dato un match perfetto con l'elemento strutturale.\n","\n","* Rif: [erode](https://docs.opencv.org/4.x/d4/d86/group__imgproc__filter.html#gaeb1e0c1033e3f6b891a25d0511362aeb)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"JjJD-Xp7HdZC"},"source":["Possiamo provarlo con un semplice esempio in scala ridotta."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VUWrgtvtHdZE","outputId":"e11ddb8a-0c58-4634-bd5e-9790f42222c9"},"outputs":[],"source":["kernel_sample = np.array([[1, 1, 1],\n","                          [1, 1, 1],\n","                          [1, 1, 1]], dtype=np.uint8)\n","\n","image_sample_1 = np.array([[0, 0, 0, 0, 0],\n","                           [0, 1, 1, 1, 0],\n","                           [0, 1, 1, 1, 0],\n","                           [0, 1, 1, 1, 0],\n","                           [0, 0, 0, 0, 0]], dtype=np.uint8)\n","\n","image_sample_2 = np.array([[0, 0, 0, 0, 0],\n","                           [0, 0, 1, 1, 0],\n","                           [0, 1, 1, 1, 0],\n","                           [0, 1, 1, 1, 0],\n","                           [0, 0, 0, 0, 0]], dtype=np.uint8)\n","\n","print('\\nEsempio erosione 1:\\n')\n","print(cv2.erode(image_sample_1, kernel_sample, iterations = 1))\n","print('\\nEsempio erosione 2:\\n')\n","print(cv2.erode(image_sample_2, kernel_sample, iterations = 1))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"O2TP3aGEHdZF"},"source":["Il parametro _iterations_, esposto dal metodo, permette di eseguire piu' passaggi del kernel sugli output mano a mano creati. L'applicazione di _n_ iterazioni di erode produrra' effetti ovviamente maggiori."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a2w3lwFOHdZG","outputId":"c339d130-9d7d-45ec-8591-8800571a6ca0"},"outputs":[],"source":["image_with_erode = cv2.erode(image, se_erode, iterations = 5)\n","\n","grid([image, image_with_erode], 1, 2, 20)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"aKeaO7lMHdZJ"},"source":["## _Con opencv e' possibile eseguire la dilatazione._"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"bHq4GusBHz7i"},"source":["Anche in questo caso, basta definire un kernel e applicarlo con il metodo adatto esposto da _opencv_."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b_uMMi8XHdZK","outputId":"4e21639e-66a2-49ba-e9a2-7778f475d508"},"outputs":[],"source":["se_dilate_size = 5\n","se_dilate_shape = (se_dilate_size, se_dilate_size)\n","se_dilate = np.ones(se_dilate_shape, np.uint8)\n","\n","print(se_dilate)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PiGaZpNWHdZL","outputId":"8dd2fbe4-c214-4a74-8261-0bdac3a7bb83"},"outputs":[],"source":["image_with_dilate = cv2.dilate(image, se_dilate, iterations = 1)\n","\n","grid([image, image_with_dilate], 1, 2, 20)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Proviamo ora con un esempio ad-hoc."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["kernel_sample = np.array([[1, 1, 1],\n","                          [1, 1, 1],\n","                          [1, 1, 1]], dtype=np.uint8)\n","\n","image_sample_1 = np.array([[0, 0, 0, 0, 0],\n","                           [0, 0, 0, 0, 0],\n","                           [0, 0, 1, 0, 0],\n","                           [0, 0, 0, 0, 0],\n","                           [0, 0, 0, 0, 0]], dtype=np.uint8)\n","\n","image_sample_2 = np.array([[0, 0, 0, 0, 0],\n","                           [0, 1, 0, 0, 0],\n","                           [0, 0, 0, 0, 0],\n","                           [0, 0, 0, 1, 0],\n","                           [0, 0, 0, 0, 0]], dtype=np.uint8)\n","\n","print('\\nEsempio dilatazione 1:\\n')\n","print(cv2.dilate(image_sample_1, kernel_sample, iterations = 1))\n","print('\\nEsempio dilatazione 2:\\n')\n","print(cv2.dilate(image_sample_2, kernel_sample, iterations = 1))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Proviamo ad eseguire un numero maggiore di iterazioni."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image_with_dilate = cv2.dilate(image, se_dilate, iterations = 3)\n","\n","grid([image, image_with_dilate], 1, 2, 20)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## _Possono essere utilizzati anche elementi strutturali di default._"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["La creazione di un elemento struttura di default, standard, avviene dopo una richiesta fatta ad _opencv_ tramite il metodo _getStructuringElement_ ed indicando forma e dimensioni desiderate. Le forme standard disponibili sono _rettangolo_, _croce_ ed _ellisse_. Se necessario e' possibile anche 'sbilanciare' il kernel scegliendo un centro diverso da quello di default.\n","\n","* Rif: [getStructuringElement](https://docs.opencv.org/4.x/d4/d86/group__imgproc__filter.html#gac342a1bb6eabf6f55c803b09268e36dc)\n","* Rif: [MorphShapes](https://docs.opencv.org/4.x/d4/d86/group__imgproc__filter.html#gac2db39b56866583a95a5680313c314ad)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sample_kernel_size = (9,9)\n","sample_kernel_rect = cv2.getStructuringElement(cv2.MORPH_RECT, sample_kernel_size)\n","sample_kernel_cross = cv2.getStructuringElement(cv2.MORPH_CROSS, sample_kernel_size)\n","sample_kernel_ellipse = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, sample_kernel_size)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(f'\\nElemento strutturale, RETTANGOLO:\\n{sample_kernel_rect}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(f'\\nElemento strutturale, CROCE:\\n{sample_kernel_cross}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(f'\\nElemento strutturale, ELLISSE:\\n{sample_kernel_ellipse}')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Se necessario, e' possibile richiedere la creazione di kernel non quadrati."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sample_kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (9, 5))\n","print(sample_kernel)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["L'anchor point, il centro, puo' venire spostato rispetto alla sua posizione di default."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sample_kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (9, 5), anchor=(6, 1))\n","print(sample_kernel)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["_**Nota**:_ il centro del kernel in una posizione differente ha effetti visivi solo su elementi a croce. In elementi come ellisse e rettangolo non si nota ma un effetto e' comunque presente: quello di connettere ogni pixel della sorgente al centro shiftato, shiftando di conseguenza anche gli output che ci si sarebbe aspettati. Lo vediamo con una dilatazione."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image_sample = np.array([[0, 0, 0, 0, 0],\n","                         [0, 0, 0, 0, 0],\n","                         [0, 0, 1, 0, 0],\n","                         [0, 0, 0, 0, 0],\n","                         [0, 0, 0, 0, 0]], dtype=np.uint8)\n","\n","print(image_sample)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["kernel_sample = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n","\n","print('\\nEsempio dilatazione 1:\\n')\n","print(cv2.morphologyEx(image_sample, cv2.MORPH_DILATE, kernel_sample, anchor=(-1, -1), iterations = 1))\n","print('\\nEsempio dilatazione 2:\\n')\n","print(cv2.morphologyEx(image_sample, cv2.MORPH_DILATE, kernel_sample, anchor=(0, 0), iterations = 1))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## _Opencv puo' combinare erosioni e dilatazioni creando operazioni avanzate._"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Per fare questo, e' possibile sfruttare il metodo esposto _morphologyEx_ indicando l'input, l'operazione richiesta e il kernel. \n","* L'input sara' la classica immagine tradotta come numpy array\n","* L'operazione va indicata fra quelle disponibili in _opencv_. ([MorphTypes](https://docs.opencv.org/4.x/d4/d86/group__imgproc__filter.html#ga7be549266bad7b2e6a04db49827f9f32))\n","* Il kernel puo' essere ottenuto da metodo _getStructuringElement_ sceliendo fra i tipi esposti, [MorphShapes](https://docs.opencv.org/4.x/d4/d86/group__imgproc__filter.html#gac2db39b56866583a95a5680313c314ad), o indicandolo custom.\n","\n","___\n","* Rif: [morphologyEx](https://docs.opencv.org/4.x/d4/d86/group__imgproc__filter.html#ga67493776e3ad1a3df63883829375201f)\n","* Rif: [getStructuringElement](https://docs.opencv.org/4.x/d4/d86/group__imgproc__filter.html#gac342a1bb6eabf6f55c803b09268e36dc)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Proviamo ad eseguire quindi l'erosione nei due modi indicati."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["kernel = np.ones((3,3), np.uint8)\n","image_with_erode_1 = cv2.erode(image, kernel, iterations=1)\n","image_with_erode_2 = cv2.morphologyEx(image, cv2.MORPH_ERODE, kernel, iterations=1)\n","difference = cv2.absdiff(image_with_erode_1, image_with_erode_2)\n","\n","grid([image, image_with_erode_1, image_with_erode_2, difference], 1, 4, 25)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Proviamo ad eseguire quindi la dilatazione nei due modi indicati."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["kernel = np.ones((3,3), np.uint8)\n","\n","image_with_dilate_1 = cv2.dilate(image, kernel, iterations=1)\n","image_with_dilate_2 = cv2.morphologyEx(image, cv2.MORPH_DILATE, kernel, iterations=1)\n","difference = cv2.absdiff(image_with_dilate_1, image_with_dilate_2)\n","\n","grid([image, image_with_dilate_1, image_with_dilate_2, difference], 1, 4, 25)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## _L'operazione di open._"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["L'operazione di open, o apertura, va ad eseguire sull'immagine di input una successione di erosione e dilatazione in questo esatto ordine. E' disponibile tramite il metodo _morphologyEx_ ma puo' essere tradotta in due passi nelle singole operazioni di _erode_ e _dilate_. Definiamo quindi il kernel."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["kernel = np.ones((5, 5), np.uint8)\n","print(kernel)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image_with_open_1 = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel, iterations=1)\n","\n","grid([image, image_with_open_1], 1, 2, 20)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Farlo in due passi non avrebbe cambiato il risultato."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image_with_open_2 = cv2.dilate(cv2.erode(image, kernel, iterations=1), kernel, iterations=1)\n","difference = cv2.absdiff(image_with_open_1, image_with_open_2)\n","\n","grid([image_with_open_1, image_with_open_2, difference], 1, 3, 25)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Proviamo ad eseguire piu' di una iterazione."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image_with_open_1 = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel, iterations=3)\n","\n","grid([image, image_with_open_1], 1, 2, 20)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## _L'operazione di close._"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["L'operazione di close, o chiusura, va ad eseguire sull'immagine di input una successione di dilatazione ed erosione in questo esatto ordine. E' disponibile tramite il metodo _morphologyEx_ ma puo' essere tradotta in due passi nelle singole operazioni di _dilate_ e _erode_. Definiamo quindi il kernel."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["kernel = np.ones((5, 5), np.uint8)\n","print(kernel)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image_with_close_1 = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel, iterations=1)\n","\n","grid([image, image_with_close_1], 1, 2, 20)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Farlo in due passi non avrebbe cambiato il risultato."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image_with_close_2 = cv2.erode(cv2.dilate(image, kernel, iterations=1), kernel, iterations=1)\n","difference = cv2.absdiff(image_with_close_1, image_with_close_2)\n","\n","grid([image_with_close_1, image_with_close_2, difference], 1, 3, 25)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Proviamo ad eseguire piu' di una iterazione."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image_with_close_1 = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel, iterations=3)\n","\n","grid([image, image_with_close_1], 1, 2, 20)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## _L'operazione gradient._"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["L'operazione gradient, o gradiente, rappresenta la differenza fra dilatazione ed erosione dell'immagine sorgente. E' disponibile tramite il metodo _morphologyEx_ ma puo' essere tradotta in tre passi nelle singole operazioni di _dilate_ e _erode_ ed una sottrazione dei risultati. Definiamo quindi il kernel."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["kernel = np.ones((5, 5), np.uint8)\n","print(kernel)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image_with_gradient_1 = cv2.morphologyEx(image, cv2.MORPH_GRADIENT, kernel, iterations=1)\n","\n","grid([image, image_with_gradient_1], 1, 2, 20)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Farlo in tre passi non avrebbe cambiato il risultato."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image_with_gradient_2 = cv2.dilate(image, kernel, iterations=1) - cv2.erode(image, kernel, iterations=1)\n","difference = cv2.absdiff(image_with_gradient_1, image_with_gradient_2)\n","\n","grid([image_with_gradient_1, image_with_gradient_2, difference], 1, 3, 25)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## _L'operazione top-hat._"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["L'operazione top-hat rappresenta la differenza fra l'input e l'apertura dell'immagine sorgente. E' disponibile tramite il metodo _morphologyEx_ ma puo' essere tradotta in tre passi nelle singole operazioni di _erode_ e _dilate_ sottratti dall'input. Definiamo quindi il kernel."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["kernel = np.ones((5, 5), np.uint8)\n","print(kernel)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image_with_that_1 = cv2.morphologyEx(image, cv2.MORPH_TOPHAT, kernel, iterations=1)\n","\n","grid([image, image_with_that_1], 1, 2, 20)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Farlo in tre passi non avrebbe cambiato il risultato."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image_with_that_2 = cv2.subtract(image, cv2.dilate(cv2.erode(image, kernel, iterations=1), kernel, iterations=1))\n","difference = cv2.absdiff(image_with_gradient_1, image_with_gradient_2)\n","\n","grid([image_with_that_1, image_with_that_2, difference], 1, 3, 25)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## _L'operazione black-hat._"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["L'operazione black-hat rappresenta la differenza fra la chiusura dell'immmagine l'input. E' disponibile tramite il metodo _morphologyEx_ ma puo' essere tradotta in tre passi nelle singole operazioni di _dilate_ e _erode_ sottratti all'input. Definiamo quindi il kernel."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["kernel = np.ones((5, 5), np.uint8)\n","print(kernel)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image_with_bhat_1 = cv2.morphologyEx(image, cv2.MORPH_BLACKHAT, kernel, iterations=1)\n","\n","grid([image, image_with_bhat_1], 1, 2, 20)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Farlo in tre passi non avrebbe cambiato il risultato."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image_with_bhat_2 = cv2.subtract(cv2.erode(cv2.dilate(image, kernel, iterations=1), kernel, iterations=1), image)\n","difference = cv2.absdiff(image_with_bhat_1, image_with_bhat_2)\n","\n","grid([image_with_bhat_1, image_with_bhat_2, difference], 1, 3, 25)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## _Altra operazione fondamentale, presente anche in opencv, e' la trasformazione Hit-And-Miss con la quale ricercare pattern specifici in immagini binarie._"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["In questo caso sara' possibile generare un kernel strutturale indicando elmenti da ignorare ed elementi/pattern da cercare che possiedano specifici valori di background e di foreground.\n","Iniziamo definendo l'immagine di test.\n","\n","Rif: [opencv tutorial](https://docs.opencv.org/4.x/db/d06/tutorial_hitOrMiss.html)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Con B ed F andiamo ad indicare i pixel di background e foreground nell'immagine binaria di esempio."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["B = 0   # background\n","F = 255 # foreground\n","\n","input_hm = np.array((\n","    [B, B, B, B, B, B, B, B],\n","    [B, F, F, F, B, B, B, F],\n","    [B, F, F, F, B, B, B, B],\n","    [B, F, F, F, B, F, B, B],\n","    [B, B, F, B, B, B, B, B],\n","    [B, B, F, B, B, F, F, B],\n","    [B, F, B, F, B, B, F, B],\n","    [B, F, F, F, B, B, B, B]), dtype=\"uint8\")\n","\n","grid([input_hm], 1, 1, 5)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Nel creare il kernel, definiamo ora i pixel di background, foreground e quelli da ignorare: B, F, e D."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["D = 0   # ignorati\n","B = -1  # background\n","F = 1   # foreground\n","\n","kernel_hm = np.array((\n","        [D, F, D],\n","        [F, B, F],\n","        [D, F, D]), dtype=\"int\")\n","\n","grid([kernel_hm], 1, 1, 5)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["L'applicazione della trasformazione abbiene nuovamente con _morphologyEx_ e, a cambiare, e' solamente il flag indicativo dell'operazione da effettuare."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["output_hm = cv2.morphologyEx(input_hm, cv2.MORPH_HITMISS, kernel_hm)\n","\n","grid([input_hm, output_hm], 1, 2, 15)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Con il kernel, siamo riusciti ad individuare l'unico pixel che, ancorato, fa match esatto con il pattern. Possiamo provare a cercare anche degli spigoli."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["kernel_hm = np.array((\n","        [D, B, B],\n","        [F, F, B],\n","        [D, F, D]), dtype=\"int\")\n","\n","grid([kernel_hm], 1, 1, 5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["output_hm = cv2.morphologyEx(input_hm, cv2.MORPH_HITMISS, kernel_hm)\n","\n","grid([input_hm, output_hm], 1, 2, 15)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Oppure dei punti isolati."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["kernel_hm = np.array((\n","        [B, B, B],\n","        [B, F, B],\n","        [B, B, B]), dtype=\"int\")\n","\n","grid([kernel_hm], 1, 1, 5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["output_hm = cv2.morphologyEx(input_hm, cv2.MORPH_HITMISS, kernel_hm)\n","\n","grid([input_hm, output_hm], 1, 2, 15)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"corso_ai","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"55b72797edd57f58696da9ac5b5536b8813fefe094e8c8c02c797501a07dae2a"}}},"nbformat":4,"nbformat_minor":0}
