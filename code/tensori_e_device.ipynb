{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fondamenti di Pytorch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effettuiamo l'import delle librerie utilizzate nell'esercitazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Di seguito i riferimenti alle pagine di documentazione, sempre utiliti:\n",
    "\n",
    "* Rif: [numpy](https://numpy.org/doc/stable/)\n",
    "* Rif: [pytorch](https://pytorch.org/docs/stable/index.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggiungiamo alcune funzioni di utilita' per semplificare la scrittura del codice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info(t : torch.Tensor):\n",
    "    print(f'\\n*****')\n",
    "    print(f'Valore:\\n{t}\\n')\n",
    "    print(f'Tipo pytohn\\t: {type(t)}')\n",
    "    print(f'Tipo\\t\\t: {t.dtype}')\n",
    "    print(f'Dimensioni\\t: {t.ndim}')\n",
    "    print(f'Forma\\t\\t: {t.shape}')\n",
    "    print(f'Dispositivo\\t: {t.device}')\n",
    "    print(f'*****\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Quando si ha a disposizione un device, e' possibile utilizzare i tensori anche al di fuori della cpu._"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partiamo creando un tensore di esempio senza specificare altro,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tensor = torch.tensor([[1, 2], [3, 4], [5, 6]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questo caso il tensore stara' su cpu, verifichiamolo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info(sample_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Verificare la presenza del device e' il primo passo per poterlo utilizzare._"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_pytorch_ mette a disposizione un sotto-modulo, _torch.cuda_, che fornisce metodi dedicati a fare questi controlli.\n",
    "\n",
    "Rif: [torch.cuda](https://pytorch.org/docs/stable/cuda.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per prima cosa controlliamo se un device abilitato ad usare CUDA e' presente. Per farlo utilizziamo il metodo **is_available** che con un valore booleano ci restituisce questa informazione.\n",
    "\n",
    "Rif: [is_available](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_gpu_present = torch.cuda.is_available()\n",
    "print(is_gpu_present)\n",
    "\n",
    "# Ulteriore modo di verificare questo, se in Google colab, e' quello di chiederlo direttamente alla console\n",
    "# !nvidia-smi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possono essere presenti anche piu' device abilitati nel sistema. Per sapere quanti, il metodo **device_count** ci viene in aiuto.\n",
    "\n",
    "Rif: [device_count](https://pytorch.org/docs/stable/generated/torch.cuda.device_count.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_devices = torch.cuda.device_count()\n",
    "print(available_devices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Quando si ha a disposizione un device, e' possibile interrogarsi sulle sue caratteristiche._"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per farlo esistono diversi metodi, sempre messi a disposizione da _torch.cuda_. Di seguito alcuni.\n",
    "\n",
    "* Rif: [get_device_name](https://pytorch.org/docs/stable/generated/torch.cuda.get_device_name.html)\n",
    "* Rif: [get_device_capability](https://pytorch.org/docs/stable/generated/torch.cuda.get_device_capability.html)\n",
    "* Rif: [get_device_properties](https://pytorch.org/docs/stable/generated/torch.cuda.get_device_properties.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ognuno di questi metodi richiede come parametro l'indice (numerico) che rappresenta il device. Nel caso di un dispositivo solo disponibile, sara' **0**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.get_device_capability(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.get_device_properties(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Un tensore, puo' essere quindi spostato su di un altro device disponibile._"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per farlo si ha a disposizione il metodo _to_ della classe **torch.Tensor**. A questo puo' essere specificato il device ed eventualmente anche l'indice.\n",
    "\n",
    "Rif: [to](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tensor_gpu = sample_tensor.to(\"cuda\")\n",
    "info(sample_tensor_gpu)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possiamo fare lo stesso, specificando anche l'indice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tensor_gpu_2 = sample_tensor.to(\"cuda:0\")\n",
    "info(sample_tensor_gpu_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Riportarlo su cpu e' altrettanto semplice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tensor_cpu = sample_tensor_gpu.to(\"cpu\")\n",
    "info(sample_tensor_cpu)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Numpy non supporta la gpu quindi il passaggio da tensore a numpy array e' invalido se il tensore sta su gpu._"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il seguente codice, se eseguito, produrra' errore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tensor_numpy = sample_tensor_gpu.numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Riportare il tensore su cpu prima della conversione risolvera' il problema. Per ottenere una copia del tensore spostato in memoria cpu e' possibile utilizzare il metodo _cpu_ sul tensore stesso.\n",
    "\n",
    "Rif: [cpu](https://pytorch.org/docs/stable/generated/torch.Tensor.cpu.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tensor_numpy = sample_tensor_gpu.cpu().numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _I tensori possono venire creati, direttamente, su di un dispositivo CUDA abilitato._"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ne possiamo vedere un esempio aggiungendo il parametro _device_ durante la creazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tensor = torch.tensor([[1, 2], [3, 4], [5, 6]], device=\"cuda\")\n",
    "info(sample_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "corso_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55b72797edd57f58696da9ac5b5536b8813fefe094e8c8c02c797501a07dae2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
