{"cells":[{"cell_type":"markdown","metadata":{"id":"9QFaY8irHdYj"},"source":["# Fondamenti di elaborazione immagini"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"DTgER4fVHkcZ"},"source":["## Effettuiamo l'import delle librerie utilizzate nell'esercitazione."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-7PVHXx_HdYp"},"outputs":[],"source":["import cv2\n","import numpy as np\n","import matplotlib as mapli\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.axes_grid1 import ImageGrid\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"L6P-3mZmHdYt"},"source":["Di seguito i riferimenti alle pagine di documentazione, sempre utiliti:\n","\n","* Rif: [numpy](https://numpy.org/doc/stable/)\n","* Rif: [opencv](https://docs.opencv.org/)\n","* Rif: [matplotlib](https://matplotlib.org/stable/index.html)"]},{"cell_type":"markdown","metadata":{"id":"KckTp-UeHdYu"},"source":["Aggiungiamo alcune funzioni di utilita' per la scrittura del codice."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4FE6_x8hHdYv"},"outputs":[],"source":["def rgb(image : np.array) -> np.array:\n","    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","def gray(image : np.array) -> np.array:\n","    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","def grid(images : list[np.array], rows : int, cols : int, size : int, colors : list[str] = None) -> None:\n","    fig = plt.figure(figsize=(size,size))\n","    grid = ImageGrid(fig, 111, nrows_ncols=(rows, cols), axes_pad=0.1)\n","\n","    if colors is not None:\n","        counter = 0\n","        for ax, im in zip(grid, images):\n","            ax.imshow(im, cmap=colors[counter])\n","            counter = (counter + 1) % len(colors)\n","        plt.show()\n","    else:\n","        for ax, im in zip(grid, images):\n","            ax.imshow(im)\n","        plt.show()"]},{"cell_type":"markdown","metadata":{"id":"4ycFRAL7HoI_"},"source":["## _La convoluzione e' una fra le piu' note tecniche di trasformazione delle immagini, utilizzata sia come tecnica di preprocessing che come tecnica applicabile all'ambito del deep learning._"]},{"cell_type":"markdown","metadata":{"id":"VFlYStn_HdYx"},"source":["Per iniziare questa operazione e' necessario definire una matrice di convoluzione o kernel. Grazie all'interscambiabilita' presente fra _numpy_ e _opencv_, e' possibile farlo definendo direttamente la matrice di numeri. Facciamo riferimento ad alcune delle matrici definite dal seguente link wikipedia:\n","\n","* Rif: [Convolution kernel](https://en.wikipedia.org/wiki/Kernel_(image_processing))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E7-gDBhHHdYy","outputId":"899d3357-8d23-42ec-998c-55d2bda11275"},"outputs":[],"source":["kernel_sample = np.array([[0, 0, 0],\n","                          [0, 1, 0],\n","                          [0, 0, 0]])\n","\n","print(kernel_sample)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image_sample = np.array([[1, 2, 3],\n","                         [4, 5, 6],\n","                         [7, 8, 9]]).astype(np.uint8)\n","\n","print(image_sample)"]},{"cell_type":"markdown","metadata":{"id":"QkvnnCSQHdY3"},"source":["Il kernel di esempio definito e':\n","* Quadrato di dimensione 3x3.\n","* Simmetrico con il centro in (1,1)\n","Per come sono stati definiti i suoi valori, ogni volta che si aggancera' ad un pixel, ne manterra' il valore senza tenere conto del 'vicinato'."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["convolution = cv2.filter2D(src=image_sample, ddepth=-1, kernel=kernel_sample)\n","print(convolution)"]},{"cell_type":"markdown","metadata":{"id":"K0XsyvxqHdY6"},"source":["Per applicare il filtro di convoluzione, il kernel, all'operazione di convoluzione, abbiamo utilizzato il metodo _filter2D_ di _opencv_. Gli argomenti passati sono semplicemente l'immagine, il kernel e la dimensione attesa per l'output. Quest'ultimo parametro, indicato da **ddepth**, se posto a -1 indica che l'output avra' stessa dimensione dell'input.\n","\n","* Rif: [filter2D](https://docs.opencv.org/4.x/d4/d86/group__imgproc__filter.html#ga27c049795ce870216ddfb366086b5a04)"]},{"cell_type":"markdown","metadata":{"id":"jvo9T7goHdY8"},"source":["## _Solamente cambiando la matrice di valori, i risultati ottenuti possono variare._ "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Proviamo ad esempio diverse tipologie di kernel. Creiamo una funzione di utilita' per semplificarci le prove."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def rgb_convolution(image : str, kernel : np.ndarray, delta : int = 0, threshold : int = 30) -> None:\n","\n","    # legge l'immagine a colori\n","    image = cv2.imread(image, cv2.IMREAD_COLOR)\n","\n","    # applichiamo il filtro di convoluzione.\n","    convolution = cv2.filter2D(src=image, ddepth=-1, kernel=kernel, delta=delta)\n","\n","    # applichiamo una sogliatura per mostrare al meglio il risultato\n","    _, thresholded = cv2.threshold(convolution, threshold, 255, cv2.THRESH_BINARY)\n","\n","    grid([rgb(image), rgb(convolution), thresholded], 1, 3, 25)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Carichiamo un'immagine di esempio."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image = './imgs/kitten.png'\n","delta = 0\n","threshold = 20"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KRqekJGmHdY4","outputId":"e2380099-951e-4b87-d003-90d9c9c17e1b"},"outputs":[],"source":["# Proviamo un kernel di ricerca gradienti.\n","kernel = np.array([[-1, -1, -1],\n","                   [-1,  8, -1],\n","                   [-1, -1, -1]])\n","\n","rgb_convolution(image, kernel, delta, threshold)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Proviamo un kernel di ricerca gradienti.\n","kernel = np.array([[ 0, -1,  0],\n","                   [-1,  4, -1],\n","                   [ 0, -1,  0]])\n","\n","rgb_convolution(image, kernel, delta, threshold)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Proviamo un kernel di ricerca linee orizzontali.\n","kernel = np.array([[-1, -1, -1],\n","                   [ 2,  2,  2],\n","                   [-1, -1, -1]])\n","\n","rgb_convolution(image, kernel, delta, threshold)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Proviamo un kernel di ricerca linee verticali.\n","kernel = np.array([[-1, 2, -1],\n","                   [-1, 2, -1],\n","                   [-1, 2, -1]])\n","\n","rgb_convolution(image, kernel, delta, threshold)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Proviamo un kernel di ricerca linee a -45°.\n","kernel = np.array([[2, -1, -1],\n","                   [-1, 2, -1],\n","                   [-1, -1, 2]])\n","\n","rgb_convolution(image, kernel, delta, threshold)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Proviamo un kernel di ricerca linee a 45°.\n","kernel = np.array([[-1, -1,  2],\n","                   [-1,  2, -1],\n","                   [ 2, -1, -1]])\n","\n","rgb_convolution(image, kernel, delta, threshold)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Proviamo un kernel di differenza.\n","kernel = np.array([[ 0,  0,  0],\n","                   [ 0,  1, -1],\n","                   [ 0,  0,  0]])\n","\n","rgb_convolution(image, kernel, delta, threshold)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Proviamo un kernel di differenza.\n","kernel = np.array([[ 0,  0,  0],\n","                   [ 1,  0, -1],\n","                   [ 0,  0,  0]])\n","\n","rgb_convolution(image, kernel, delta, threshold)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Proviamo un kernel di differenza. (Roberts)\n","kernel = np.array([[ 0,  0, -1],\n","                   [ 0,  1,  0],\n","                   [ 0,  0,  0]])\n","\n","rgb_convolution(image, kernel, delta, threshold)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Proviamo un kernel di differenza. (Prewitt)\n","kernel = (np.array([[ 1, 0, -1],\n","                    [ 1, 0, -1],\n","                    [ 1, 0, -1]]).astype(np.float32)) / 3\n","\n","rgb_convolution(image, kernel, delta, threshold)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Proviamo un kernel di differenza. (Sobel)\n","kernel = (np.array([[ 1, 0, -1],\n","                    [ 2, 0, -2],\n","                    [ 1, 0, -1]]).astype(np.float32)) / 4\n","\n","rgb_convolution(image, kernel, delta, threshold)"]},{"cell_type":"markdown","metadata":{"id":"IZ34MwIyHuPQ"},"source":["Per applicare una semplice sfocatura, si puo', ad esempio, assegnare ad ogni pixel un valore dato dall'equo contributo di tutti i suoi vicini (lui stesso compreso). Con un kernel quadrato 3x3, centrato sul pixel, si andra' a considerare lui e tutti i suoi vicini. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OdlVGcucHdY_","outputId":"eaf3faad-574d-4112-8fc7-7122997c9f47"},"outputs":[],"source":["# Proviamo un kernel di sfocatura.\n","kernel = (np.array([[ 1, 1, 1],\n","                    [ 1, 1, 1],\n","                    [ 1, 1, 1]]).astype(np.float32)) / 9\n","\n","rgb_convolution(image, kernel, 0, 255)"]},{"cell_type":"markdown","metadata":{"id":"JjJD-Xp7HdZC"},"source":["Per esagerare con la sfocatura, possiamo chiedere il contributo di un vicinato piu' grande: ad esempio un 7x7 attorno al pixel in esame."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Proviamo un kernel di sfocatura.\n","kernel = np.array([[1, 1, 1, 1, 1, 1, 1],\n","                   [1, 1, 1, 1, 1, 1, 1],\n","                   [1, 1, 1, 1, 1, 1, 1],\n","                   [1, 1, 1, 1, 1, 1, 1],\n","                   [1, 1, 1, 1, 1, 1, 1],\n","                   [1, 1, 1, 1, 1, 1, 1],\n","                   [1, 1, 1, 1, 1, 1, 1]]).astype(np.float32) / 49\n","\n","rgb_convolution(image, kernel, 0, 255)"]},{"cell_type":"markdown","metadata":{"id":"O2TP3aGEHdZF"},"source":["Aumentiamo il kernel."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a2w3lwFOHdZG","outputId":"c339d130-9d7d-45ec-8591-8800571a6ca0"},"outputs":[],"source":["# Proviamo un kernel di sfocatura.\n","kernel = np.ones((9, 9), np.float32) / 81\n","\n","rgb_convolution(image, kernel, 0, 255)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b_uMMi8XHdZK","outputId":"4e21639e-66a2-49ba-e9a2-7778f475d508"},"outputs":[],"source":["# Proviamo un kernel di smoothing.\n","kernel = np.array([[ 0, -1,  0],\n","                   [-1,  5, -1],\n","                   [ 0, -1,  0]])\n","\n","rgb_convolution(image, kernel, 0, 255)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"corso_ai","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"55b72797edd57f58696da9ac5b5536b8813fefe094e8c8c02c797501a07dae2a"}}},"nbformat":4,"nbformat_minor":0}
